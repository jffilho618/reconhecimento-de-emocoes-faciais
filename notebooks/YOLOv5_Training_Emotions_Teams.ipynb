{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üß† Treinamento YOLOv5 - Emo√ß√µes e Times\n",
    "\n",
    "Este notebook treina dois modelos YOLOv5:\n",
    "- **Modelo 1**: Reconhecimento de emo√ß√µes faciais\n",
    "- **Modelo 2**: Reconhecimento de escudos de times de futebol\n",
    "\n",
    "## üìã Estrutura do Dataset\n",
    "```\n",
    "images/\n",
    "‚îú‚îÄ‚îÄ faces/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ train/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ images/\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ labels/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ test/\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ images/\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ labels/\n",
    "‚îî‚îÄ‚îÄ teams/\n",
    "    ‚îú‚îÄ‚îÄ train/\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ images/\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ labels/\n",
    "    ‚îî‚îÄ‚îÄ test/\n",
    "        ‚îú‚îÄ‚îÄ images/\n",
    "        ‚îî‚îÄ‚îÄ labels/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## üîß 1. Configura√ß√£o Inicial e Depend√™ncias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Verificar GPU\n",
    "!nvidia-smi\n",
    "\n",
    "# Instalar depend√™ncias\n",
    "!pip install ultralytics roboflow supervision\n",
    "\n",
    "# Clonar YOLOv5 (caso necess√°rio)\n",
    "!git clone https://github.com/ultralytics/yolov5.git\n",
    "%cd yolov5\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drive"
   },
   "source": [
    "## üíæ 2. Conectar ao Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Definir caminhos base\n",
    "DRIVE_PATH = '/content/drive/MyDrive'\n",
    "PROJECT_PATH = f'{DRIVE_PATH}/YOLOv5_Models'\n",
    "DATASET_PATH = f'{PROJECT_PATH}/images'\n",
    "\n",
    "# Criar estrutura de pastas se n√£o existir\n",
    "os.makedirs(PROJECT_PATH, exist_ok=True)\n",
    "os.makedirs(f'{PROJECT_PATH}/models', exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Projeto salvo em: {PROJECT_PATH}\")\n",
    "print(f\"üóÇÔ∏è Datasets em: {DATASET_PATH}\")\n",
    "print(f\"ü§ñ Modelos ser√£o salvos em: {PROJECT_PATH}/models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_prep"
   },
   "source": [
    "## üìä 3. Prepara√ß√£o dos Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify_data"
   },
   "outputs": [],
   "source": [
    "# Verificar estrutura dos dados\n",
    "def verify_dataset_structure(base_path, dataset_name):\n",
    "    \"\"\"\n",
    "    Verifica se a estrutura do dataset est√° correta\n",
    "    \"\"\"\n",
    "    dataset_path = f\"{base_path}/{dataset_name}\"\n",
    "    \n",
    "    print(f\"üîç Verificando dataset: {dataset_name}\")\n",
    "    \n",
    "    for split in ['train', 'test']:\n",
    "        images_path = f\"{dataset_path}/{split}/images\"\n",
    "        labels_path = f\"{dataset_path}/{split}/labels\"\n",
    "        \n",
    "        if os.path.exists(images_path) and os.path.exists(labels_path):\n",
    "            img_count = len([f for f in os.listdir(images_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "            lbl_count = len([f for f in os.listdir(labels_path) if f.endswith('.txt')])\n",
    "            \n",
    "            print(f\"  üìÇ {split}: {img_count} imagens, {lbl_count} labels\")\n",
    "            \n",
    "            if img_count != lbl_count:\n",
    "                print(f\"  ‚ö†Ô∏è Aviso: N√∫mero de imagens e labels n√£o coincidem em {split}\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå Pasta {split} n√£o encontrada ou incompleta\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Verificar ambos os datasets\n",
    "verify_dataset_structure(DATASET_PATH, 'faces')\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "verify_dataset_structure(DATASET_PATH, 'teams')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config_faces"
   },
   "source": [
    "## üòÄ 4. Configura√ß√£o para Emo√ß√µes Faciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_faces_config"
   },
   "outputs": [],
   "source": "# Configura√ß√£o do dataset de emo√ß√µes\nfaces_config = {\n    'train': f'{DATASET_PATH}/faces/train/images',\n    'val': f'{DATASET_PATH}/faces/test/images',  # Usando test como valida√ß√£o\n    'nc': 5,  # N√∫mero de classes\n    'names': ['anger', 'fear', 'happy', 'neutral', 'sad']  # Ordem exata do data.yaml\n}\n\n# Salvar configura√ß√£o\nfaces_yaml_path = '/content/faces_dataset.yaml'\nwith open(faces_yaml_path, 'w') as f:\n    yaml.dump(faces_config, f, default_flow_style=False)\n\nprint(\"üìù Configura√ß√£o do dataset de emo√ß√µes:\")\nprint(yaml.dump(faces_config, default_flow_style=False))\n\n# Verificar algumas imagens de exemplo\nsample_images = list(Path(faces_config['train']).glob('*.jpg'))[:3]\nprint(f\"\\nüñºÔ∏è Exemplos de imagens de emo√ß√µes ({len(sample_images)} de {len(list(Path(faces_config['train']).glob('*.jpg')))} total):\")\nfor img_path in sample_images:\n    print(f\"  üì∑ {img_path.name}\")\n    display(Image(str(img_path), width=150))"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_faces"
   },
   "source": [
    "## üöÄ 5. Treinamento - Modelo de Emo√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_emotions_model"
   },
   "outputs": [],
   "source": [
    "# Par√¢metros de treinamento para emo√ß√µes\n",
    "EMOTIONS_EPOCHS = 100\n",
    "EMOTIONS_BATCH_SIZE = 16\n",
    "EMOTIONS_IMG_SIZE = 640\n",
    "\n",
    "print(\"üé≠ Iniciando treinamento do modelo de emo√ß√µes...\")\n",
    "print(f\"üìä √âpocas: {EMOTIONS_EPOCHS}\")\n",
    "print(f\"üì¶ Batch size: {EMOTIONS_BATCH_SIZE}\")\n",
    "print(f\"üñºÔ∏è Tamanho da imagem: {EMOTIONS_IMG_SIZE}\")\n",
    "\n",
    "# Comando de treinamento\n",
    "!python train.py \\\n",
    "  --img {EMOTIONS_IMG_SIZE} \\\n",
    "  --batch {EMOTIONS_BATCH_SIZE} \\\n",
    "  --epochs {EMOTIONS_EPOCHS} \\\n",
    "  --data {faces_yaml_path} \\\n",
    "  --weights yolov5s.pt \\\n",
    "  --project {PROJECT_PATH}/runs \\\n",
    "  --name emotions_model \\\n",
    "  --cache \\\n",
    "  --device 0\n",
    "\n",
    "print(\"\\n‚úÖ Treinamento de emo√ß√µes conclu√≠do!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config_teams"
   },
   "source": [
    "## ‚öΩ 6. Configura√ß√£o para Times de Futebol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_teams_config"
   },
   "outputs": [],
   "source": "# Configura√ß√£o do dataset de times\nteams_config = {\n    'train': f'{DATASET_PATH}/teams/train/images',\n    'val': f'{DATASET_PATH}/teams/test/images',  # Usando test como valida√ß√£o\n    'nc': 20,  # N√∫mero de classes (conforme data.yaml)\n    'names': [\n        'arsenal', 'aston-villa-new', 'bournemouth', 'brentford', 'brighton', \n        'burnley', 'chelsea', 'crystal-palace', 'everton', 'fulham', \n        'liverpool', 'luton', 'mancity', 'manutd', 'newcastle', \n        'nottingham', 'sheffield', 'tottenham', 'westham', 'wolves'\n    ]  # Ordem exata do data.yaml\n}\n\n# Salvar configura√ß√£o\nteams_yaml_path = '/content/teams_dataset.yaml'\nwith open(teams_yaml_path, 'w') as f:\n    yaml.dump(teams_config, f, default_flow_style=False)\n\nprint(\"üìù Configura√ß√£o do dataset de times:\")\nprint(yaml.dump(teams_config, default_flow_style=False))\n\n# Verificar algumas imagens de exemplo\nsample_images = list(Path(teams_config['train']).glob('*.jpg'))[:3]\nprint(f\"\\nüñºÔ∏è Exemplos de imagens de times ({len(sample_images)} de {len(list(Path(teams_config['train']).glob('*.jpg')))} total):\")\nfor img_path in sample_images:\n    print(f\"  üì∑ {img_path.name}\")\n    display(Image(str(img_path), width=150))"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train_teams"
   },
   "source": [
    "## üöÄ 7. Treinamento - Modelo de Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_teams_model"
   },
   "outputs": [],
   "source": [
    "# Par√¢metros de treinamento para times\n",
    "TEAMS_EPOCHS = 150\n",
    "TEAMS_BATCH_SIZE = 16\n",
    "TEAMS_IMG_SIZE = 640\n",
    "\n",
    "print(\"‚öΩ Iniciando treinamento do modelo de times...\")\n",
    "print(f\"üìä √âpocas: {TEAMS_EPOCHS}\")\n",
    "print(f\"üì¶ Batch size: {TEAMS_BATCH_SIZE}\")\n",
    "print(f\"üñºÔ∏è Tamanho da imagem: {TEAMS_IMG_SIZE}\")\n",
    "\n",
    "# Comando de treinamento\n",
    "!python train.py \\\n",
    "  --img {TEAMS_IMG_SIZE} \\\n",
    "  --batch {TEAMS_BATCH_SIZE} \\\n",
    "  --epochs {TEAMS_EPOCHS} \\\n",
    "  --data {teams_yaml_path} \\\n",
    "  --weights yolov5s.pt \\\n",
    "  --project {PROJECT_PATH}/runs \\\n",
    "  --name teams_model \\\n",
    "  --cache \\\n",
    "  --device 0\n",
    "\n",
    "print(\"\\n‚úÖ Treinamento de times conclu√≠do!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluate"
   },
   "source": [
    "## üìä 8. Avalia√ß√£o dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate_models"
   },
   "outputs": [],
   "source": [
    "# Encontrar os melhores modelos\n",
    "emotions_best = f\"{PROJECT_PATH}/runs/emotions_model/weights/best.pt\"\n",
    "teams_best = f\"{PROJECT_PATH}/runs/teams_model/weights/best.pt\"\n",
    "\n",
    "print(\"üìà Resultados do treinamento:\")\n",
    "print(\"\\nüé≠ MODELO DE EMO√á√ïES:\")\n",
    "if os.path.exists(emotions_best):\n",
    "    print(f\"‚úÖ Modelo salvo: {emotions_best}\")\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    results_path = f\"{PROJECT_PATH}/runs/emotions_model/results.png\"\n",
    "    if os.path.exists(results_path):\n",
    "        display(Image(results_path, width=800))\n",
    "else:\n",
    "    print(\"‚ùå Modelo de emo√ß√µes n√£o encontrado\")\n",
    "\n",
    "print(\"\\n‚öΩ MODELO DE TIMES:\")\n",
    "if os.path.exists(teams_best):\n",
    "    print(f\"‚úÖ Modelo salvo: {teams_best}\")\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    results_path = f\"{PROJECT_PATH}/runs/teams_model/results.png\"\n",
    "    if os.path.exists(results_path):\n",
    "        display(Image(results_path, width=800))\n",
    "else:\n",
    "    print(\"‚ùå Modelo de times n√£o encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test"
   },
   "source": [
    "## üß™ 9. Teste dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_models"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image as PILImage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def test_model(model_path, test_image_path, class_names):\n",
    "    \"\"\"\n",
    "    Testa um modelo YOLOv5 em uma imagem\n",
    "    \"\"\"\n",
    "    # Carregar modelo\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path, force_reload=True)\n",
    "    model.eval()\n",
    "    \n",
    "    # Fazer predi√ß√£o\n",
    "    results = model(test_image_path)\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    results.show()\n",
    "    \n",
    "    # Detalhes da predi√ß√£o\n",
    "    predictions = results.pandas().xyxy[0]\n",
    "    if len(predictions) > 0:\n",
    "        for idx, pred in predictions.iterrows():\n",
    "            class_name = class_names[int(pred['class'])]\n",
    "            confidence = pred['confidence']\n",
    "            print(f\"üìä Detectado: {class_name} (confian√ßa: {confidence:.2f})\")\n",
    "    else:\n",
    "        print(\"‚ùå Nenhuma detec√ß√£o encontrada\")\n",
    "\n",
    "# Testar modelo de emo√ß√µes\n",
    "if os.path.exists(emotions_best):\n",
    "    print(\"üé≠ Testando modelo de emo√ß√µes:\")\n",
    "    # Pegar uma imagem de teste\n",
    "    test_faces = list(Path(f'{DATASET_PATH}/faces/test/images').glob('*.jpg'))\n",
    "    if test_faces:\n",
    "        test_model(emotions_best, str(test_faces[0]), faces_config['names'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Testar modelo de times\n",
    "if os.path.exists(teams_best):\n",
    "    print(\"‚öΩ Testando modelo de times:\")\n",
    "    # Pegar uma imagem de teste\n",
    "    test_teams = list(Path(f'{DATASET_PATH}/teams/test/images').glob('*.jpg'))\n",
    "    if test_teams:\n",
    "        test_model(teams_best, str(test_teams[0]), teams_config['names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export"
   },
   "source": [
    "## üíæ 10. Exportar Modelos para Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_models"
   },
   "outputs": [],
   "source": [
    "def export_model_to_drive(source_path, destination_name):\n",
    "    \"\"\"\n",
    "    Copia modelo treinado para pasta espec√≠fica no Drive\n",
    "    \"\"\"\n",
    "    if os.path.exists(source_path):\n",
    "        destination_path = f\"{PROJECT_PATH}/models/{destination_name}\"\n",
    "        shutil.copy2(source_path, destination_path)\n",
    "        \n",
    "        # Verificar tamanho do arquivo\n",
    "        size_mb = os.path.getsize(destination_path) / (1024 * 1024)\n",
    "        \n",
    "        print(f\"‚úÖ {destination_name} exportado com sucesso!\")\n",
    "        print(f\"üìÅ Caminho: {destination_path}\")\n",
    "        print(f\"üìä Tamanho: {size_mb:.1f} MB\")\n",
    "        return destination_path\n",
    "    else:\n",
    "        print(f\"‚ùå Modelo n√£o encontrado: {source_path}\")\n",
    "        return None\n",
    "\n",
    "print(\"üì¶ Exportando modelos treinados para Google Drive...\")\n",
    "print(\"\\nüé≠ MODELO DE EMO√á√ïES:\")\n",
    "emotions_exported = export_model_to_drive(emotions_best, \"emotion_model.pt\")\n",
    "\n",
    "print(\"\\n‚öΩ MODELO DE TIMES:\")\n",
    "teams_exported = export_model_to_drive(teams_best, \"team_model.pt\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üéâ TREINAMENTO CONCLU√çDO COM SUCESSO!\")\n",
    "print(\"\\nüìã RESUMO DOS MODELOS:\")\n",
    "\n",
    "if emotions_exported:\n",
    "    print(f\"üé≠ Emo√ß√µes: {emotions_exported}\")\n",
    "    print(f\"   Classes: {', '.join(faces_config['names'])}\")\n",
    "\n",
    "if teams_exported:\n",
    "    print(f\"‚öΩ Times: {teams_exported}\")\n",
    "    print(f\"   Classes: {', '.join(teams_config['names'])}\")\n",
    "\n",
    "print(\"\\nüí° PR√ìXIMOS PASSOS:\")\n",
    "print(\"1. Baixe os arquivos .pt do Google Drive\")\n",
    "print(\"2. Coloque-os nas pastas dos containers:\")\n",
    "print(\"   - emotion_model.pt ‚Üí ai-face-service/models/\")\n",
    "print(\"   - team_model.pt ‚Üí ai-team-service/models/\")\n",
    "print(\"3. Execute o sistema distribu√≠do com docker-compose\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## ‚¨áÔ∏è 11. Download Direto dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_models"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(\"‚¨áÔ∏è Fazendo download dos modelos treinados...\")\n",
    "\n",
    "# Download do modelo de emo√ß√µes\n",
    "if emotions_exported and os.path.exists(emotions_exported):\n",
    "    print(\"\\nüé≠ Baixando modelo de emo√ß√µes...\")\n",
    "    files.download(emotions_exported)\n",
    "\n",
    "# Download do modelo de times\n",
    "if teams_exported and os.path.exists(teams_exported):\n",
    "    print(\"\\n‚öΩ Baixando modelo de times...\")\n",
    "    files.download(teams_exported)\n",
    "\n",
    "print(\"\\n‚úÖ Downloads iniciados! Verifique a pasta de downloads do seu navegador.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}